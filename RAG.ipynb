{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b523111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d49123",
   "metadata": {},
   "source": [
    "# Première API pour récupérer tous les ids récents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d325621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_offers(limit=100, skip=0):\n",
    "    # URL de l'API\n",
    "    url = \"https://civiweb-api-prd.azurewebsites.net/api/Offers/search\"\n",
    "\n",
    "    # Corps de la requête (payload)\n",
    "    payload = {\n",
    "        \"limit\": limit,\n",
    "        \"skip\": skip,\n",
    "        \"latest\": [\"true\"],\n",
    "        \"method\": [\"null\"],\n",
    "        \"activitySectorId\": [],\n",
    "        \"missionsTypesIds\": [],\n",
    "        \"missionsDurations\": [],\n",
    "        \"gerographicZones\": [],\n",
    "        \"countriesIds\": [],\n",
    "        \"studiesLevelId\": [],\n",
    "        \"companiesSizes\": [],\n",
    "        \"specializationsIds\": [],\n",
    "        \"entreprisesIds\": [0],\n",
    "        \"missionStartDate\": None,\n",
    "        \"query\": None\n",
    "    }\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Effectuer la requête POST\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    # Vérifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    # Afficher le résultat\n",
    "    print(f\"Code de statut: {response.status_code}\")\n",
    "        \n",
    "    return response.json()\n",
    "\n",
    "#search_offers(2,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c4a7f",
   "metadata": {},
   "source": [
    "# Appelle par Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd279d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Récupération des données réussies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 230682,\n",
       " 'organizationName': 'DEMGY NORMANDIE',\n",
       " 'missionTitle': 'ERP SYSTEMS ANALYST (H/F)',\n",
       " 'missionDuration': 6,\n",
       " 'viewCounter': 152,\n",
       " 'candidateCounter': 8,\n",
       " 'missionType': 'VIE',\n",
       " 'missionTypeEn': 'VIE',\n",
       " 'organizationPresentation': '',\n",
       " 'organizationUrlImage': '',\n",
       " 'organizationImage': None,\n",
       " 'organizationPathImage': None,\n",
       " 'pathImage': '',\n",
       " 'image': None,\n",
       " 'activitySectorN1': 'INDUSTRIES CHIMIQUES ET PLASTURGIE',\n",
       " 'activitySectorN2': None,\n",
       " 'activitySectorN3': None,\n",
       " 'activitySectorN1Id': 100008,\n",
       " 'ca': '19027',\n",
       " 'effectif': 159,\n",
       " 'organizationCountryCounter': '',\n",
       " 'organizationExpertise': None,\n",
       " 'cityAffectationId': -1,\n",
       " 'cityName': 'TACOMA (WA)',\n",
       " 'cityNameEn': 'TACOMA (WA)',\n",
       " 'activitySectorOfferId': 8,\n",
       " 'levelStudyIds': None,\n",
       " 'specializations': None,\n",
       " 'missionDescription': 'Présentation de la société :\\n\\nDEMGY Pacific est une entreprise américaine spécialisée dans la fabrication de pièces plastiques et métalliques pour l’aéronautique. Basée à Tacoma (Washington), elle fait partie du groupe DEMGY depuis 2025\\n\\nPoste et missions :\\n\\nERP system optimization:  \\n- Current challenge:  the IQMS ERP system contains data and information that is unreliable.  This lack of reliability results in scheduling issues, production/delivery delays, and overproduction \\n- Objective:\\no Work with the Demgy Pacific team to analyze causes for ERP data issues and the reasons.  Recommend and implement solutions to eliminate the need for workarounds\\no Analyze MRP run quantity settings that are currently leading to production inefficiencies (e.g., minimum run quantities, work order bundling, etc).  Recommend and implement solutions that will result in optimized inventory and equipment utilization\\no Analyze BOM settings and provide recommendations to improve BOM cycle time and material consumption accuracy\\n\\nERP system consolidation:  \\n- Current challenge:  Demgy Pacific currently operates with two ERP systems -- IQMS for the Plastics Division and Jobboss for the Metals Division.  This results in lack of visibility between the two divisions, inability to share resources, and the requirement for dual accounting systems, ordering systems, purchasing systems, etc. \\n- Objective:  work with the Demgy Pacific team to develop and implement a plan to consolidate all Jobboss activity into IQMS\\n\\n\\n\\n',\n",
       " 'creationDate': '2025-10-08T13:27:17.233',\n",
       " 'missionStartDate': '2026-01-01T00:00:00',\n",
       " 'missionEndDate': '2026-07-01T00:00:00',\n",
       " 'startBroadcastDate': '2025-10-09T00:00:00',\n",
       " 'durationBroadcast': 90,\n",
       " 'organizationId': 13540,\n",
       " 'missionProfile': 'Proven experience in ERP system optimization, data integrity, and process improvement\\nFamiliarity with MRP logic, BOM structures, and production planning\\nStrong analytical skills with the ability to identify root causes and implement sustainable solutions\\nExcellent communication and collaboration skills across cross-functional teams\\nAbility to manage projects independently and drive change in a manufacturing environment',\n",
       " 'countryId': '733',\n",
       " 'countryName': 'ETATS-UNIS',\n",
       " 'countryNameEn': 'UNITED STATES',\n",
       " 'reference': 'VIE231682',\n",
       " 'contactName': 'Monsieur                                           VERGER Benjamin',\n",
       " 'indemnite': 3674,\n",
       " 'idMotifDesactivationOffre': 0,\n",
       " 'contactEmail': 'recrutement@demgy.com',\n",
       " 'cityAffectation': 'TACOMA (WA)',\n",
       " 'idNomenclatureSecteur': None,\n",
       " 'externalJobId': None,\n",
       " 'dateCandidature': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_offer_details(offer_id):\n",
    "    url = f\"https://civiweb-api-prd.azurewebsites.net/api/Offers/details/{offer_id}\"\n",
    "    # Headers (optionnel pour un GET simple)\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    # Effectuer la requête GET\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # Vérifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    print(\"   Récupération des données réussies\")\n",
    "    return response.json()\n",
    "\n",
    "get_offer_details(230682)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea715e18",
   "metadata": {},
   "source": [
    "## Fonction pour clean les données manquantes (appelés directment dans la création des chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2414016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_offer_data(offer_data):\n",
    "    print(\"   Nettoyage des données\")\n",
    "    \"\"\"Nettoie et complète les données manquantes\"\"\"\n",
    "    return {\n",
    "        \"reference\": offer_data.get(\"reference\", \"N/A\"),\n",
    "        \"organizationName\": offer_data.get(\"organizationName\", \"Entreprise non spécifiée\"),\n",
    "        \"missionTitle\": offer_data.get(\"missionTitle\", \"Titre non spécifié\"),\n",
    "        \"missionDescription\": offer_data.get(\"missionDescription\", \"Description non disponible\"),\n",
    "        \"missionProfile\": offer_data.get(\"missionProfile\", \"Profil non spécifié\"),\n",
    "        \"countryName\": offer_data.get(\"countryName\", \"Pays non spécifié\"),\n",
    "        \"cityName\": offer_data.get(\"cityName\", \"Ville non spécifiée\"),\n",
    "        \"activitySectorN1\": offer_data.get(\"activitySectorN1\", \"Secteur non spécifié\"),\n",
    "        \"missionDuration\": offer_data.get(\"missionDuration\", \"Durée non spécifiée\"),\n",
    "        \"indemnite\": offer_data.get(\"indemnite\", \"Non spécifié\"),\n",
    "        \"missionStartDate\": offer_data.get(\"missionStartDate\", \"Date non spécifiée\"),\n",
    "        \"contactEmail\": offer_data.get(\"contactEmail\", \"Email non disponible\"),\n",
    "        \"missionType\": offer_data.get(\"missionType\", \"Type non spécifié\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb015",
   "metadata": {},
   "source": [
    "# Création des chunks pour notre RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_chunks_for_rag(offer_data):\n",
    "    \"\"\"Crée 2 chunks optimisés pour le RAG\"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    # 1. Nettoyer les données brutes\n",
    "    cleaned_offer = clean_offer_data(offer_data)\n",
    "\n",
    "    # 2. Extraire les métadonnées depuis les données nettoyées\n",
    "    common_metadata = {\n",
    "        \"offer_id\": cleaned_offer.get(\"reference\"),  \n",
    "        \"company\": cleaned_offer.get(\"organizationName\"),\n",
    "        \"title\": cleaned_offer.get(\"missionTitle\"),\n",
    "        \"country\": cleaned_offer.get(\"countryName\"),\n",
    "        \"city\": cleaned_offer.get(\"cityName\"),\n",
    "        \"sector\": cleaned_offer.get(\"activitySectorN1\"),\n",
    "        \"duration_months\": cleaned_offer.get(\"missionDuration\"),\n",
    "        \"salary_eur\": cleaned_offer.get(\"indemnite\"),\n",
    "        \"start_date\": cleaned_offer.get(\"missionStartDate\"),\n",
    "        \"contact_email\": cleaned_offer.get(\"contactEmail\"),\n",
    "        \"mission_type\": cleaned_offer.get(\"missionType\")\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    # CHUNK 1: Description de la mission\n",
    "    chunk1_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityName')}, {offer_data.get('countryName')}\n",
    "    Secteur d'activité: {offer_data.get('activitySectorN1')}\n",
    "    Durée: {offer_data.get('missionDuration')} mois\n",
    "    Indemnité: {offer_data.get('indemnite')} € par mois\n",
    "    Description de la mission: {offer_data.get('missionDescription', 'Non spécifiée')}\"\"\"\n",
    "\n",
    "    new_chunk = {\n",
    "        \"content\": chunk1_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"mission_description\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_desc\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"   Taille du chunk de Description (caractères) : {len(new_chunk['content'])}\")\n",
    "    chunks.append(new_chunk)\n",
    "    \n",
    "    # CHUNK 2: Profil recherché\n",
    "    chunk2_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityName')}, {offer_data.get('countryName')}\n",
    "    Secteur: {offer_data.get('activitySectorN1')}\n",
    "    Profil recherché: {offer_data.get('missionProfile', 'Non spécifié')}\"\"\"\n",
    "\n",
    "    new_chunk2 = {\n",
    "        \"content\": chunk2_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"candidate_profile\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_profile\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    chunks.append(new_chunk2)\n",
    "    print(f\"   Taille du chunk de Profil (caractères) : {len(new_chunk2['content'])}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b65f7",
   "metadata": {},
   "source": [
    "# Create the embeding of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af59a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration OpenAI\n",
    "api_key = os.environ.get(\"API_KEY_OPENAI\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573b4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Crée un embedding pour un texte avec OpenAI\n",
    "    \n",
    "    Args:\n",
    "        text: Le texte à embedder\n",
    "        \n",
    "    Returns:\n",
    "        Liste de floats représentant l'embedding\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"  # 1536 dimensions, $0.02/1M tokens\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b9ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_batch(chunks: List[Dict], batch_size: int = 100) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Crée les embeddings pour tous les chunks avec traitement par batch\n",
    "    \n",
    "    Args:\n",
    "        chunks: Liste des chunks à embedder\n",
    "        batch_size: Nombre de chunks à traiter par batch (max 100 pour OpenAI)\n",
    "        \n",
    "    Returns:\n",
    "        Liste des chunks enrichis avec leurs embeddings\n",
    "    \"\"\"\n",
    "    enriched_chunks = []\n",
    "    \n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        print(f\"Traitement du batch {i//batch_size + 1} ({len(batch)} chunks)...\")\n",
    "        \n",
    "        # Extraire les contenus textuels\n",
    "        texts = [chunk[\"content\"] for chunk in batch]\n",
    "        \n",
    "        # Créer les embeddings en batch (plus efficace)\n",
    "        response = client.embeddings.create(\n",
    "            input=texts,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        # Associer chaque embedding à son chunk\n",
    "        for j, chunk in enumerate(batch):\n",
    "            enriched_chunk = chunk.copy()\n",
    "            enriched_chunk[\"embedding\"] = response.data[j].embedding\n",
    "            enriched_chunks.append(enriched_chunk)\n",
    "        \n",
    "        # Rate limiting (optionnel mais recommandé)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"✅ {len(enriched_chunks)} embeddings créés\")\n",
    "    return enriched_chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246978d",
   "metadata": {},
   "source": [
    "# Let's save our chunks and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab50aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, filename):\n",
    "    \"\"\"Sauvegarde les données en JSON\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✅ Données sauvegardées dans {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f810db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_numpy(chunks_with_embeddings, filename=\"vie_embeddings.npz\"):\n",
    "    \"\"\"\n",
    "    Sauvegarde les embeddings en format NumPy pour un chargement rapide\n",
    "    \"\"\"\n",
    "    embeddings = np.array([chunk[\"embedding\"] for chunk in chunks_with_embeddings])\n",
    "    metadata = [chunk[\"metadata\"] for chunk in chunks_with_embeddings]\n",
    "    contents = [chunk[\"content\"] for chunk in chunks_with_embeddings]\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        filename,\n",
    "        embeddings=embeddings,\n",
    "        metadata=metadata,\n",
    "        contents=contents\n",
    "    )\n",
    "    print(f\"✅ Embeddings sauvegardés dans {filename}\")\n",
    "    print(f\"   Shape: {embeddings.shape}\")\n",
    "\n",
    "\n",
    "# Fonction pour charger les embeddings sauvegardés\n",
    "def load_embeddings(filename=\"vie_embeddings.npz\"):\n",
    "    \"\"\"Charge les embeddings depuis un fichier NumPy\"\"\"\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    return {\n",
    "        'embeddings': data['embeddings'],\n",
    "        'metadata': data['metadata'],\n",
    "        'contents': data['contents']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f371a9",
   "metadata": {},
   "source": [
    "# Let's call everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f12cf07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PIPELINE RAG - OFFRES VIE\n",
      "================================================================================\n",
      "\n",
      "[1/5] Recherche des offres VIE...\n",
      "Code de statut: 200\n",
      "✅ 10 offres trouvées\n",
      "\n",
      "[2/5] Récupération des détails et création des chunks...\n",
      "  Traitement offre 1/10: 227934\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 2907\n",
      "   Taille du chunk de Profil (caractères) : 828\n",
      "✅ 2 chunks créés\n",
      "\n",
      "  Traitement offre 2/10: 230682\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 1771\n",
      "   Taille du chunk de Profil (caractères) : 615\n",
      "✅ 4 chunks créés\n",
      "\n",
      "  Traitement offre 3/10: 230189\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 2624\n",
      "   Taille du chunk de Profil (caractères) : 629\n",
      "✅ 6 chunks créés\n",
      "\n",
      "  Traitement offre 4/10: 230718\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 1267\n",
      "   Taille du chunk de Profil (caractères) : 1730\n",
      "✅ 8 chunks créés\n",
      "\n",
      "  Traitement offre 5/10: 230713\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 1323\n",
      "   Taille du chunk de Profil (caractères) : 1729\n",
      "✅ 10 chunks créés\n",
      "\n",
      "  Traitement offre 6/10: 230722\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 2468\n",
      "   Taille du chunk de Profil (caractères) : 283\n",
      "✅ 12 chunks créés\n",
      "\n",
      "  Traitement offre 7/10: 230720\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 2549\n",
      "   Taille du chunk de Profil (caractères) : 293\n",
      "✅ 14 chunks créés\n",
      "\n",
      "  Traitement offre 8/10: 230716\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 1581\n",
      "   Taille du chunk de Profil (caractères) : 281\n",
      "✅ 16 chunks créés\n",
      "\n",
      "  Traitement offre 9/10: 230706\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 2764\n",
      "   Taille du chunk de Profil (caractères) : 1734\n",
      "✅ 18 chunks créés\n",
      "\n",
      "  Traitement offre 10/10: 230532\n",
      "   Récupération des données réussies\n",
      "   Nettoyage des données\n",
      "   Taille du chunk de Description (caractères) : 1106\n",
      "   Taille du chunk de Profil (caractères) : 536\n",
      "✅ 20 chunks créés\n",
      "\n",
      "\n",
      "[3/5] Création des embeddings OpenAI...\n",
      "Traitement du batch 1 (20 chunks)...\n",
      "✅ 20 embeddings créés\n",
      "\n",
      "[4/5] Sauvegarde des données...\n",
      "✅ Données sauvegardées dans vie_rag_data.json\n",
      "✅ Embeddings sauvegardés dans vie_embeddings.npz\n",
      "   Shape: (20, 1536)\n",
      "\n",
      "[5/5] Statistiques finales\n",
      "================================================================================\n",
      "Nombre d'offres traitées: 10\n",
      "Nombre de chunks: 20\n",
      "Dimension des embeddings: 1536\n",
      "Tokens estimés: ~7,247\n",
      "Coût estimé: ~$0.0001\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ÉTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=10)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "# La structure de retour peut varier, adaptez selon l'API\n",
    "# Supposons que l'API retourne une liste d'IDs ou d'objets simplifiés\n",
    "offer_ids = []\n",
    "offer_ids = [item.get(\"id\") for item in offers_response[\"result\"] if item.get(\"id\") is not None]\n",
    "\n",
    "print(f\"✅ {len(offer_ids)} offres trouvées\")\n",
    "\n",
    "# ÉTAPE 2: Récupérer les détails et créer les chunks\n",
    "print(\"\\n[2/5] Récupération des détails et création des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids[:10], 1):  # Limitez pour le test\n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{min(10, len(offer_ids))}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"✅ {len(all_chunks)} chunks créés\\n\")\n",
    "\n",
    "# ÉTAPE 3: Créer les embeddings\n",
    "print(\"\\n[3/5] Création des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des données...\")\n",
    "save_to_json(chunks_with_embeddings, \"vie_rag_data.json\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "\n",
    "# ÉTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre d'offres traitées: {len(offer_ids[:10])}\")\n",
    "print(f\"Nombre de chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estimés: ~{total_tokens:,}\")\n",
    "print(f\"Coût estimé: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f7eb",
   "metadata": {},
   "source": [
    "# Now let's ask a question and embed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fcfa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Quelle est la meilleur Offre pour faire de la Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd87e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = np.array([get_text_embedding(question)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d5200",
   "metadata": {},
   "source": [
    "# Comparison bewtween our embedding vector and our embedding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160b890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def find_closest_embedding(\n",
    "    question_embeddings: np.array,\n",
    "    text_embeddings: np.ndarray,\n",
    "    top_n: int = 3,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Calculer les similarités avec tous les embeddings\n",
    "    similarites = cosine_similarity(question_embeddings, text_embeddings)[0]\n",
    "\n",
    "    # Récupérer les top_n index et scores\n",
    "    top_index = np.argsort(similarites)[-top_n:][::-1]  # Tri décroissant\n",
    "    top_scores = similarites[top_index]\n",
    "\n",
    "    return top_scores, top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142df887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 embeddings les plus proches:\n",
      " \n",
      "- Embedding 14: Score = 0.4515\n",
      "metadata : {'offer_id': 'VIE231716', 'company': 'EQUANS', 'title': 'DATA ENGINEER HF', 'country': 'AUSTRALIE', 'city': 'SYDNEY                                  ', 'sector': 'ENERGIES', 'duration_months': 12, 'salary_eur': 3206, 'start_date': '2026-01-01T00:00:00', 'contact_email': 'Annabelle.eggerling@equans.com ', 'mission_type': 'VIE', 'chunk_type': 'mission_description', 'chunk_id': '230716_desc'}\n",
      "contents : Offre VIE VIE231716 - DATA ENGINEER HF\n",
      "    Entreprise: EQUANS\n",
      "    Localisation: SYDNEY                                  , AUSTRALIE\n",
      "    Secteur d'activité: ENERGIES\n",
      "    Durée: 12 mois\n",
      "    Indemnité: 3206 € par mois\n",
      "    Description de la mission: Présentation de la société :\n",
      "Equans is a world leader in the energy and services sector, with annual revenues of nearly €19,2 billion* and almost 800,000 projects. Equans has leading positions in Europe, which is the result of the history of energy construction in these countries, and strong presences in North and South America and in Oceania.\n",
      "With nearly 90,000 highly skilled employees, Equans has a strong geographic footprint, anchored by historic local brands. Equans provides its customers with excellent technical expertise in the design, installation, maintenance and operation of multi-technical facilities. This know-how is based on key skills. First of all, in electrical and thermal engineering - two strong points that help accelerate the reduction of our clients' carbon footprint - but also in ventilation, refrigeration, mechanics and robotics, fire protection, energy renovation, digital solutions, IT, cyber security and telecommunications.\n",
      "The combination of these expertise allows us to offer efficient and optimised solutions at all stages of the energy chain, from production, storage and transport to usage.\n",
      "(*) Turnover 2024 consolidated\n",
      "\n",
      "\n",
      "\n",
      "Poste et missions :\n",
      "Participer à la mise en œuvre de l’écosysteme data pour ANZ et au développement de logiciels embarquant des modèles variés (inc. Computer vision)\n",
      "\n",
      "\n",
      "\n",
      "- Embedding 15: Score = 0.4254\n",
      "metadata : {'offer_id': 'VIE231716', 'company': 'EQUANS', 'title': 'DATA ENGINEER HF', 'country': 'AUSTRALIE', 'city': 'SYDNEY                                  ', 'sector': 'ENERGIES', 'duration_months': 12, 'salary_eur': 3206, 'start_date': '2026-01-01T00:00:00', 'contact_email': 'Annabelle.eggerling@equans.com ', 'mission_type': 'VIE', 'chunk_type': 'candidate_profile', 'chunk_id': '230716_profile'}\n",
      "contents : Offre VIE VIE231716 - DATA ENGINEER HF\n",
      "    Entreprise: EQUANS\n",
      "    Localisation: SYDNEY                                  , AUSTRALIE\n",
      "    Secteur: ENERGIES\n",
      "    Profil recherché: Profile motivé pour accompagner ANZ dans sa transformation Data. \n",
      "Anglais Courant – Français est un plus\n",
      "\n",
      "- Embedding 12: Score = 0.3749\n",
      "metadata : {'offer_id': 'VIE231720', 'company': 'BOUYGUES ENERGIES & SERVICES', 'title': 'VIE INGENIEUR(E) CYBER HF', 'country': 'AUSTRALIE', 'city': 'SYDNEY                                  ', 'sector': 'ENERGIES', 'duration_months': 12, 'salary_eur': 3206, 'start_date': '2026-01-01T00:00:00', 'contact_email': 'Camille.ble@equans.com', 'mission_type': 'VIE', 'chunk_type': 'mission_description', 'chunk_id': '230720_desc'}\n",
      "contents : Offre VIE VIE231720 - VIE INGENIEUR(E) CYBER HF\n",
      "    Entreprise: BOUYGUES ENERGIES & SERVICES\n",
      "    Localisation: SYDNEY                                  , AUSTRALIE\n",
      "    Secteur d'activité: ENERGIES\n",
      "    Durée: 12 mois\n",
      "    Indemnité: 3206 € par mois\n",
      "    Description de la mission: Présentation de la société :\n",
      "EQUANS est la branche Energie & Services du groupe Bouygues. Avec 97 000 collaborateurs, une présence dans 20 pays et un CA de 17 milliards d’euros, nous nous positionnons aujourd’hui comme le leader mondial des services multi techniques dont les activités sont au cœur des transitions environnementales, industrielles et numériques.   \n",
      "Organisé en 6 expertises : Electrique, CVC, Réfrigération, Mécanique, Digital et informatique, Facility management, nos corps de métiers représentent notre capacité à innover et à nous adapter pour fournir des services à forte valeur ajoutée pour nos clients \n",
      "Enraciné dans une histoire plus que centenaire issue des sociétés Axima et Ineo, le chiffre d’affaires d’EQUANS France atteint les 5 milliards d’euros. \n",
      " \n",
      "Les réseaux électriques évoluent partout dans le monde pour faire face à une demande croissante en énergie.\n",
      " \n",
      "Depuis l’étude de conception (in-house) jusqu’à la mise en service, en passant par le dimensionnement, la réalisation et le financement, BYES accompagne ses clients dans la mise en place d’infrastructures évolutives, fiables et performantes, grâce à des technologies innovantes.\n",
      " \n",
      "Rejoindre notre équipe, c'est intégrer une entreprise leader dans le secteur des énergies.\n",
      "\n",
      "\n",
      "\n",
      "Poste et missions :\n",
      "En tant qu’ingénieur(e) cyber, vous jouez un rôle central dans la réussite de nos projets.\n",
      "Vos missions sont :\n",
      "Analyse des risques et des vulnérabilités\n",
      "•\tIdentifier les menaces potentielles sur les systèmes informatiques et industriels.\n",
      "•\tÉvaluer les risques liés aux infrastructures critiques (centrales solaires, éoliennes, réseaux intelligents…).\n",
      " Mise en place de solutions de sécurité\n",
      "•\tDéployer des outils de protection : pare-feu, antivirus, systèmes de détection d’intrusion.\n",
      "•\tConfigurer et maintenir des architectures sécurisées pour les réseaux et les systèmes.\n",
      "Gestion des accès et des identités\n",
      "•\tDéfinir les politiques d’accès aux données et aux systèmes.\n",
      "•\tMettre en œuvre des solutions d’authentification forte et de gestion des identités.\n",
      "Tests et audits\n",
      "Sensibilisation et formation\n",
      "Veille technologique et réglementaire\n",
      "•\tSuivre l’évolution des menaces et des technologies de protection.\n",
      "•\tS’assurer du respect des normes et réglementations\n",
      "Réponse aux incidents\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_embeddings = load_embeddings(\"vie_embeddings.npz\")\n",
    "text_embeddings = loaded_embeddings['embeddings']\n",
    "top_scores, top_index = find_closest_embedding(question_embeddings, text_embeddings)\n",
    "\n",
    "top_results = []\n",
    "\n",
    "print(\"Top 3 embeddings les plus proches:\\n \")\n",
    "for score, idx in zip(top_scores, top_index):\n",
    "    print(f\"- Embedding {idx}: Score = {score:.4f}\")\n",
    "    print(f\"metadata : {loaded_embeddings['metadata'][idx]}\")\n",
    "    print(f\"contents : {loaded_embeddings['contents'][idx]}\")\n",
    "    top_results.append(loaded_embeddings['contents'][idx])\n",
    "\n",
    "    # loaded_embeddings['metadata'][idx] PAS UTILISER POUR L'INSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43189f",
   "metadata": {},
   "source": [
    "# We Use a LLM to answer our question using the closest embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf51178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La meilleure offre pour faire de la data est l'offre \"VIE VIE231716 - DATA ENGINEER HF\" chez EQUANS à Sydney, Australie. Cette offre est spécifiquement axée sur la mise en œuvre de l'écosystème data pour ANZ et le développement de logiciels embarquant des modèles variés, y compris la vision par ordinateur.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concaténer les top-N segments en un seul contexte\n",
    "context = \"\\n\".join(top_results)\n",
    "prompt = f\"Contexte :\\n{context}\\n\\nQuestion : {question}\\nRéponse :\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Tu es un assistant spécialisé dans la recherche d'information à partir de documents fournis. Tes réponses doivent absolument provenir du contexte fourni.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
