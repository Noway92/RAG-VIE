{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b523111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ceb116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Last_Refresh import get_last_refresh_date, update_last_refresh_date\n",
    "from BDD import save_embeddings_numpy, load_embeddings, append_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d49123",
   "metadata": {},
   "source": [
    "# API to fetch all VIE Id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d325621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_offers(limit=100, skip=0):\n",
    "    # URL de l'API\n",
    "    url = \"https://civiweb-api-prd.azurewebsites.net/api/Offers/search\"\n",
    "\n",
    "    # Corps de la requ√™te (payload)\n",
    "    payload = {\n",
    "        \"limit\": limit,\n",
    "        \"skip\": skip,\n",
    "        \"latest\": [\"true\"],\n",
    "        \"method\": [\"null\"],\n",
    "        \"activitySectorId\": [],\n",
    "        \"missionsTypesIds\": [\"1\"],\n",
    "        \"missionsDurations\": [],\n",
    "        \"gerographicZones\": [],\n",
    "        \"countriesIds\": [],\n",
    "        \"studiesLevelId\": [],\n",
    "        \"companiesSizes\": [],\n",
    "        \"specializationsIds\": [],\n",
    "        \"entreprisesIds\": [0],\n",
    "        \"missionStartDate\": None,\n",
    "        \"query\": None\n",
    "    }\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Effectuer la requ√™te POST\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    # V√©rifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    # Afficher le r√©sultat\n",
    "    print(f\"Code de statut: {response.status_code}\")\n",
    "        \n",
    "    return response.json()\n",
    "\n",
    "#search_offers(10,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c4a7f",
   "metadata": {},
   "source": [
    "# API to fetch all the data for each ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd279d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offer_details(offer_id):\n",
    "    url = f\"https://civiweb-api-prd.azurewebsites.net/api/Offers/details/{offer_id}\"\n",
    "    # Headers (optionnel pour un GET simple)\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    # Effectuer la requ√™te GET\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # V√©rifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    print(\"   R√©cup√©ration des donn√©es r√©ussies\")\n",
    "    return response.json()\n",
    "\n",
    "#get_offer_details(227664)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9caeb",
   "metadata": {},
   "source": [
    "## Methods to compute application rate of the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b3e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_offer_data(offer_data):\n",
    "    \"\"\"Am√©liore les donn√©es avec des m√©triques calcul√©es\"\"\"\n",
    "    candidates = offer_data.get('candidateCounter', 0)\n",
    "    views = offer_data.get('viewCounter', 0)\n",
    "    \n",
    "    # Calcul du taux de postulation\n",
    "    application_rate = 0\n",
    "    if views > 0:\n",
    "        application_rate = round((candidates / views) * 100, 1)\n",
    "    \n",
    "    # Cat√©gorisation de la comp√©tition\n",
    "    competition_level = \"FAIBLE\"\n",
    "    if application_rate > 10:\n",
    "        competition_level = \"√âLEV√âE\"\n",
    "    elif application_rate > 5:\n",
    "        competition_level = \"MOYENNE\"\n",
    "    \n",
    "    return {\n",
    "        **offer_data,\n",
    "        \"application_rate\": application_rate,  \n",
    "        \"competition_level\": competition_level,  \n",
    "        \"candidates_count\": candidates,\n",
    "        \"views_count\": views\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea715e18",
   "metadata": {},
   "source": [
    "## Methods to clean the data, (Used in the creating chunk method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2414016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_offer_data(offer_data):\n",
    "    print(\"   Nettoyage des donn√©es\")\n",
    "    \"\"\"Nettoie et compl√®te les donn√©es manquantes\"\"\"\n",
    "    return {\n",
    "        \"reference\": offer_data.get(\"reference\", \"N/A\"),\n",
    "        \"organizationName\": offer_data.get(\"organizationName\", \"Entreprise non sp√©cifi√©e\"),\n",
    "        \"missionTitle\": offer_data.get(\"missionTitle\", \"Titre non sp√©cifi√©\"),\n",
    "        \"missionDescription\": offer_data.get(\"missionDescription\", \"Description non disponible\"),\n",
    "        \"missionProfile\": offer_data.get(\"missionProfile\", \"Profil non sp√©cifi√©\"),\n",
    "        \"countryNameEn\": offer_data.get(\"countryNameEn\", \"Pays non sp√©cifi√©\"),\n",
    "        \"cityNameEn\": offer_data.get(\"cityNameEn\", \"Ville non sp√©cifi√©e\"),\n",
    "        \"activitySectorN1\": offer_data.get(\"activitySectorN1\", \"Secteur non sp√©cifi√©\"),\n",
    "        \"missionDuration\": offer_data.get(\"missionDuration\", \"Dur√©e non sp√©cifi√©e\"),\n",
    "        \"indemnite\": offer_data.get(\"indemnite\", \"Non sp√©cifi√©\"),\n",
    "        \"missionStartDate\": offer_data.get(\"missionStartDate\", \"Date non sp√©cifi√©e\"),\n",
    "        \"creationDate\": offer_data.get(\"creationDate\",\"Date non sp√©cifi√©e\"),\n",
    "        \"contactEmail\": offer_data.get(\"contactEmail\", \"Email non disponible\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb015",
   "metadata": {},
   "source": [
    "# Creating chunks method\n",
    "\n",
    "We are dividing our chunks into content and metadata.\n",
    "\n",
    "We will only apply embedding on our content.\n",
    "\n",
    "Metadata will allow to use some filters when fetching the embeddings in the ChromaDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_chunks_for_rag(offer_data):\n",
    "    \"\"\"Cr√©e 2 chunks optimis√©s pour le RAG\"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    # 1. Nettoyer les donn√©es brutes\n",
    "    cleaned_offer = clean_offer_data(offer_data)\n",
    "\n",
    "    # 2. Calculer le taux de postulation √† l'offre\n",
    "    enhanced_data = enhance_offer_data(offer_data)\n",
    "\n",
    "    # 2. Extraire les m√©tadonn√©es depuis les donn√©es nettoy√©es\n",
    "    common_metadata = {\n",
    "        \"offer_reference\": cleaned_offer.get(\"reference\"),  \n",
    "        \"company\": cleaned_offer.get(\"organizationName\"),\n",
    "        \"title\": cleaned_offer.get(\"missionTitle\"),\n",
    "        \"country\": cleaned_offer.get(\"countryNameEn\"),\n",
    "        \"city\": cleaned_offer.get(\"cityNameEn\"),\n",
    "        \"sector\": cleaned_offer.get(\"activitySectorN1\"),\n",
    "        \"duration_months\": cleaned_offer.get(\"missionDuration\"),\n",
    "        \"salary_eur\": cleaned_offer.get(\"indemnite\"),\n",
    "        \"start_date\": cleaned_offer.get(\"missionStartDate\"),\n",
    "        \"creation_date\": cleaned_offer.get(\"creationDate\"),\n",
    "        \"contact_email\": cleaned_offer.get(\"contactEmail\"),\n",
    "        # Rest is comming from enhanced_data\n",
    "        \"application_rate\": enhanced_data[\"application_rate\"],\n",
    "        \"competition_level\": enhanced_data[\"competition_level\"], \n",
    "        \"candidates_count\": enhanced_data[\"candidates_count\"],\n",
    "        \"views_count\": enhanced_data[\"views_count\"]\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    # CHUNK 1: Description de la mission\n",
    "    chunk1_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityNameEn')}, {offer_data.get('countryNameEn')}\n",
    "    Secteur d'activit√©: {offer_data.get('activitySectorN1')}\n",
    "    Dur√©e: {offer_data.get('missionDuration')} mois\n",
    "    Indemnit√©: {offer_data.get('indemnite')} ‚Ç¨ par mois\n",
    "    Description de la mission: {offer_data.get('missionDescription', 'Non sp√©cifi√©e')}\"\"\"\n",
    "\n",
    "    new_chunk = {\n",
    "        \"content\": chunk1_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"mission_description\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_description\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"   Taille du chunk de Description (caract√®res) : {len(new_chunk['content'])}\")\n",
    "    chunks.append(new_chunk)\n",
    "    \n",
    "    # CHUNK 2: Profil recherch√©\n",
    "    chunk2_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityNameEn')}, {offer_data.get('countryNameEn')}\n",
    "    Secteur d'activit√©: {offer_data.get('activitySectorN1')}\n",
    "    Profil recherch√©: {offer_data.get('missionProfile', 'Non sp√©cifi√©')}\"\"\"\n",
    "\n",
    "    new_chunk2 = {\n",
    "        \"content\": chunk2_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"candidate_profile\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_profile\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    chunks.append(new_chunk2)\n",
    "    print(f\"   Taille du chunk de Profil (caract√®res) : {len(new_chunk2['content'])}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b65f7",
   "metadata": {},
   "source": [
    "# Create the embeding of the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af59a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration OpenAI\n",
    "api_key = os.environ.get(\"API_KEY_OPENAI\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674a7e3",
   "metadata": {},
   "source": [
    "###  Method to embed the question that we will ask the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "573b4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Cr√©e un embedding pour un texte avec OpenAI\n",
    "    \n",
    "    Args:\n",
    "        text: Le texte √† embedder\n",
    "        \n",
    "    Returns:\n",
    "        Liste de floats repr√©sentant l'embedding\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"  # 1536 dimensions, $0.02/1M tokens\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b0cb4",
   "metadata": {},
   "source": [
    "###  Method to create our embeddings dataset\n",
    "\n",
    "We are using batch to optimize API calls and reduce latency. \n",
    "\n",
    "This approach processes multiple texts in a single request instead of making individual calls for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b9ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_batch(chunks: List[Dict], batch_size: int = 100) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Cr√©e les embeddings pour tous les chunks avec traitement par batch\n",
    "    \n",
    "    Args:\n",
    "        chunks: Liste des chunks √† embedder\n",
    "        batch_size: Nombre de chunks √† traiter par batch (max 100 pour OpenAI)\n",
    "        \n",
    "    Returns:\n",
    "        Liste des chunks enrichis avec leurs embeddings\n",
    "    \"\"\"\n",
    "    enriched_chunks = []\n",
    "    \n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        print(f\"Traitement du batch {i//batch_size + 1} ({len(batch)} chunks)...\")\n",
    "        \n",
    "        # Extraire les contenus textuels\n",
    "        texts = [chunk[\"content\"] for chunk in batch]\n",
    "        \n",
    "        # Cr√©er les embeddings en batch (plus efficace)\n",
    "        response = client.embeddings.create(\n",
    "            input=texts,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        # Associer chaque embedding √† son chunk\n",
    "        for j, chunk in enumerate(batch):\n",
    "            enriched_chunk = chunk.copy()\n",
    "            enriched_chunk[\"embedding\"] = response.data[j].embedding\n",
    "            enriched_chunks.append(enriched_chunk)\n",
    "        \n",
    "        # Rate limiting (optionnel mais recommand√©)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"‚úÖ {len(enriched_chunks)} embeddings cr√©√©s\")\n",
    "    return enriched_chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f371a9",
   "metadata": {},
   "source": [
    "# Creation of the Pipeline : create the dataset embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# √âTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=10000)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "# La structure de retour peut varier, adaptez selon l'API\n",
    "# Supposons que l'API retourne une liste d'IDs ou d'objets simplifi√©s\n",
    "offer_ids = []\n",
    "offer_ids = [item.get(\"id\") for item in offers_response[\"result\"] if item.get(\"id\") is not None]\n",
    "\n",
    "print(f\"‚úÖ {len(offer_ids)} offres trouv√©es\")\n",
    "\n",
    "# √âTAPE 2: R√©cup√©rer les d√©tails et cr√©er les chunks\n",
    "print(\"\\n[2/5] R√©cup√©ration des d√©tails et cr√©ation des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids, 1):  \n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{len(offer_ids)}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"‚úÖ {len(all_chunks)} chunks cr√©√©s\\n\")\n",
    "\n",
    "# √âTAPE 3: Cr√©er les embeddings\n",
    "print(\"\\n[3/5] Cr√©ation des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des nouvelles donn√©es...\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "# We save the current date\n",
    "update_last_refresh_date()\n",
    "\n",
    "# √âTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre de nouvelles offres trait√©es: {len(offer_ids)}\")\n",
    "print(f\"Nombre de nouveaux chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des nouveaux embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estim√©s: ~{total_tokens:,}\")\n",
    "print(f\"Co√ªt estim√©: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de1645",
   "metadata": {},
   "source": [
    "# Creation of the Pipeline : Add new embeddings in the curent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41761b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PIPELINE RAG - Nouvelles OFFRES VIE\n",
      "================================================================================\n",
      "\n",
      "[1/5] Recherche des offres VIE...\n",
      "Code de statut: 200\n",
      "üìÖ Dernier rafra√Æchissement: 2025-10-15 13:56:29.187000\n",
      "‚úÖ 32 nouvelles offres depuis le dernier rafra√Æchissement\n",
      "‚úÖ Last_refresh mis √† jour: 2025-10-16T12:11:01.703\n",
      "\n",
      "[2/5] R√©cup√©ration des d√©tails et cr√©ation des chunks...\n",
      "  Traitement offre 1/32: 230924\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1921\n",
      "   Taille du chunk de Profil (caract√®res) : 1701\n",
      "‚úÖ 2 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 2/32: 230960\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1817\n",
      "   Taille du chunk de Profil (caract√®res) : 861\n",
      "‚úÖ 4 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 3/32: 230928\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 3896\n",
      "   Taille du chunk de Profil (caract√®res) : 1259\n",
      "‚úÖ 6 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 4/32: 230949\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2919\n",
      "   Taille du chunk de Profil (caract√®res) : 928\n",
      "‚úÖ 8 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 5/32: 230950\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2992\n",
      "   Taille du chunk de Profil (caract√®res) : 639\n",
      "‚úÖ 10 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 6/32: 230955\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2092\n",
      "   Taille du chunk de Profil (caract√®res) : 625\n",
      "‚úÖ 12 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 7/32: 230962\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2074\n",
      "   Taille du chunk de Profil (caract√®res) : 1011\n",
      "‚úÖ 14 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 8/32: 230938\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1793\n",
      "   Taille du chunk de Profil (caract√®res) : 905\n",
      "‚úÖ 16 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 9/32: 230936\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1793\n",
      "   Taille du chunk de Profil (caract√®res) : 905\n",
      "‚úÖ 18 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 10/32: 230952\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2989\n",
      "   Taille du chunk de Profil (caract√®res) : 1031\n",
      "‚úÖ 20 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 11/32: 230954\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1498\n",
      "   Taille du chunk de Profil (caract√®res) : 516\n",
      "‚úÖ 22 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 12/32: 230953\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1493\n",
      "   Taille du chunk de Profil (caract√®res) : 518\n",
      "‚úÖ 24 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 13/32: 230961\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2999\n",
      "   Taille du chunk de Profil (caract√®res) : 195\n",
      "‚úÖ 26 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 14/32: 230947\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2500\n",
      "   Taille du chunk de Profil (caract√®res) : 1067\n",
      "‚úÖ 28 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 15/32: 230946\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2342\n",
      "   Taille du chunk de Profil (caract√®res) : 684\n",
      "‚úÖ 30 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 16/32: 230940\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2386\n",
      "   Taille du chunk de Profil (caract√®res) : 841\n",
      "‚úÖ 32 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 17/32: 230934\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2470\n",
      "   Taille du chunk de Profil (caract√®res) : 2468\n",
      "‚úÖ 34 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 18/32: 230923\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2414\n",
      "   Taille du chunk de Profil (caract√®res) : 715\n",
      "‚úÖ 36 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 19/32: 230941\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 4091\n",
      "   Taille du chunk de Profil (caract√®res) : 1257\n",
      "‚úÖ 38 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 20/32: 230932\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 615\n",
      "   Taille du chunk de Profil (caract√®res) : 1315\n",
      "‚úÖ 40 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 21/32: 230945\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 987\n",
      "   Taille du chunk de Profil (caract√®res) : 1065\n",
      "‚úÖ 42 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 22/32: 230939\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1793\n",
      "   Taille du chunk de Profil (caract√®res) : 905\n",
      "‚úÖ 44 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 23/32: 230937\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1793\n",
      "   Taille du chunk de Profil (caract√®res) : 905\n",
      "‚úÖ 46 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 24/32: 230935\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1793\n",
      "   Taille du chunk de Profil (caract√®res) : 905\n",
      "‚úÖ 48 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 25/32: 230933\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1793\n",
      "   Taille du chunk de Profil (caract√®res) : 905\n",
      "‚úÖ 50 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 26/32: 230943\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2992\n",
      "   Taille du chunk de Profil (caract√®res) : 847\n",
      "‚úÖ 52 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 27/32: 230927\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2657\n",
      "   Taille du chunk de Profil (caract√®res) : 616\n",
      "‚úÖ 54 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 28/32: 230948\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 1734\n",
      "   Taille du chunk de Profil (caract√®res) : 534\n",
      "‚úÖ 56 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 29/32: 230944\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2355\n",
      "   Taille du chunk de Profil (caract√®res) : 2159\n",
      "‚úÖ 58 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 30/32: 230942\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2374\n",
      "   Taille du chunk de Profil (caract√®res) : 2505\n",
      "‚úÖ 60 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 31/32: 230929\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 809\n",
      "   Taille du chunk de Profil (caract√®res) : 1504\n",
      "‚úÖ 62 chunks cr√©√©s\n",
      "\n",
      "  Traitement offre 32/32: 230925\n",
      "   R√©cup√©ration des donn√©es r√©ussies\n",
      "   Nettoyage des donn√©es\n",
      "   Taille du chunk de Description (caract√®res) : 2614\n",
      "   Taille du chunk de Profil (caract√®res) : 3448\n",
      "‚úÖ 64 chunks cr√©√©s\n",
      "\n",
      "\n",
      "[3/5] Cr√©ation des embeddings OpenAI...\n",
      "Traitement du batch 1 (64 chunks)...\n",
      "‚úÖ 64 embeddings cr√©√©s\n",
      "\n",
      "[4/5] Sauvegarde des donn√©es...\n",
      "‚úÖ Embeddings sauvegard√©s dans vie_embeddings.npz\n",
      "   Shape: (64, 1536)\n",
      "\n",
      "[5/5] Statistiques finales\n",
      "================================================================================\n",
      "Nombre d'offres trait√©es: 32\n",
      "Nombre de chunks: 64\n",
      "Dimension des embeddings: 1536\n",
      "Tokens estim√©s: ~26,608\n",
      "Co√ªt estim√©: ~$0.0005\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - Nouvelles OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# √âTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=100000)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "last_refresh_date = get_last_refresh_date()\n",
    "print(f\"üìÖ Dernier rafra√Æchissement: {last_refresh_date}\")\n",
    "\n",
    "offer_ids = []\n",
    "offer_ids = [\n",
    "    item.get(\"id\") for item in offers_response[\"result\"] \n",
    "    if (item.get(\"id\") is not None and \n",
    "        datetime.fromisoformat(item.get(\"creationDate\")) > last_refresh_date)\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ {len(offer_ids)} nouvelles offres depuis le dernier rafra√Æchissement\")\n",
    "# Mettre √† jour Last_refresh apr√®s le traitement\n",
    "update_last_refresh_date()\n",
    "\n",
    "# √âTAPE 2: R√©cup√©rer les d√©tails et cr√©er les chunks\n",
    "print(\"\\n[2/5] R√©cup√©ration des d√©tails et cr√©ation des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids, 1):  \n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{len(offer_ids)}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"‚úÖ {len(all_chunks)} chunks cr√©√©s\\n\")\n",
    "\n",
    "# √âTAPE 3: Cr√©er les embeddings\n",
    "print(\"\\n[3/5] Cr√©ation des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des donn√©es...\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "\n",
    "# √âTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre d'offres trait√©es: {len(offer_ids)}\")\n",
    "print(f\"Nombre de chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estim√©s: ~{total_tokens:,}\")\n",
    "print(f\"Co√ªt estim√©: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f7eb",
   "metadata": {},
   "source": [
    "# Now let's ask a question and embed it !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fcfa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"Je Cherche un VIE de minimum 1 an, je suis orient√©e en Data et IA mais j'aime aussi faire du d√©veloppement web. Peux tu me donner les meilleurs offres pour moi. Sachant que je cherche une offre pour Octobre 2025\"\n",
    "question = \"Je Cherche un VIE de minimum 1 an, je suis orient√©e en Data et IA mais j'aime aussi faire du d√©veloppement web. Peux tu me donner les meilleurs offres pour moi. Si possible priorise les offres en cor√©e du sud\"\n",
    "# question = \"Je Cherche un VIE en Asie de l'Est  pour faire de la data ou de l'IA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd87e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = np.array([get_text_embedding(question)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d5200",
   "metadata": {},
   "source": [
    "# Comparison bewtween our embedding database and our embedding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160b890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def find_closest_embedding(\n",
    "    question_embeddings: np.array,\n",
    "    text_embeddings: np.ndarray,\n",
    "    top_n: int = 3,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Calculer les similarit√©s avec tous les embeddings\n",
    "    similarites = cosine_similarity(question_embeddings, text_embeddings)[0]\n",
    "\n",
    "    # R√©cup√©rer les top_n index et scores\n",
    "    top_index = np.argsort(similarites)[-top_n:][::-1]  # Tri d√©croissant\n",
    "    top_scores = similarites[top_index]\n",
    "\n",
    "    return top_scores, top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142df887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 embeddings les plus proches:\n",
      " \n",
      "- Embedding 1: Score = 0.6616\n",
      "- Embedding 7: Score = 0.6284\n",
      "- Embedding 0: Score = 0.6262\n",
      "- Embedding 45: Score = 0.6128\n",
      "- Embedding 47: Score = 0.6117\n",
      "- Embedding 17: Score = 0.6117\n",
      "- Embedding 15: Score = 0.6110\n",
      "- Embedding 49: Score = 0.6109\n",
      "- Embedding 43: Score = 0.6108\n",
      "- Embedding 39: Score = 0.6096\n"
     ]
    }
   ],
   "source": [
    "loaded_embeddings = load_embeddings(\"vie_embeddings.npz\")\n",
    "text_embeddings = loaded_embeddings['embeddings']\n",
    "top_scores, top_index = find_closest_embedding(question_embeddings, text_embeddings, 10)\n",
    "\n",
    "top_results = []\n",
    "\n",
    "print(\"Top 10 embeddings les plus proches:\\n \")\n",
    "for score, idx in zip(top_scores, top_index):\n",
    "    top_results.append(f\"<OFFRE {idx}>\")\n",
    "    print(f\"- Embedding {idx}: Score = {score:.4f}\")\n",
    "    #print(f\"metadata : {loaded_embeddings['metadata'][idx]}\")\n",
    "    #print(f\"contents : {loaded_embeddings['contents'][idx]}\")\n",
    "    metadata = json.dumps(loaded_embeddings['metadata'][idx])\n",
    "    value = metadata+loaded_embeddings['contents'][idx]\n",
    "    top_results.append(value)\n",
    "    top_results.append(f\"</OFFRE {idx}>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43189f",
   "metadata": {},
   "source": [
    "# We Use a LLM to answer our question using the 10 closest embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cf51178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parmi les offres disponibles dans le contexte, l'offre qui se rapproche le plus de votre profil orient√© en Data et IA est l'**OFFRE 1** :\n",
      "\n",
      "- **Titre** : VIE SOLUTION ARCHITECT IA JUNIOR (H/F)\n",
      "- **Entreprise** : THUASNE\n",
      "- **Localisation** : KANSAS CITY, UNITED STATES\n",
      "- **Dur√©e** : 18 mois\n",
      "- **Indemnit√©** : 3393 ‚Ç¨ par mois\n",
      "- **Profil recherch√©** : \n",
      "  - Dipl√¥me Bac+5 en informatique, science des donn√©es, IA ou domaine connexe.\n",
      "  - 1 √† 3 ans d'exp√©rience dans des projets d'IA.\n",
      "  - Comp√©tences en Python, concepts d'IA/ML, familiarit√© avec TensorFlow, PyTorch, Scikit-learn, et plateformes de cloud computing (AWS, Azure, GCP).\n",
      "\n",
      "Malheureusement, aucune offre sp√©cifiquement en Cor√©e du Sud n'est mentionn√©e dans le contexte fourni.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concat√©ner les top-N segments en un seul contexte\n",
    "context = \"\\n\".join(top_results)\n",
    "\n",
    "prompt = f\"Contexte :\\n{context}\\n\\nQuestion : {question}\\nR√©ponse :\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Tu es un assistant sp√©cialis√© dans la recherche d'information √† partir de documents fournis. Tes r√©ponses doivent absolument provenir du contexte fourni.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
