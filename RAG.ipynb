{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b523111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ceb116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Last_Refresh import get_last_refresh_date, update_last_refresh_date\n",
    "from BDD import save_embeddings_numpy, load_embeddings, append_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d49123",
   "metadata": {},
   "source": [
    "# API to fetch all VIE Id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_offers(limit=100, skip=0):\n",
    "    # URL de l'API\n",
    "    url = \"https://civiweb-api-prd.azurewebsites.net/api/Offers/search\"\n",
    "\n",
    "    # Corps de la requête (payload)\n",
    "    payload = {\n",
    "        \"limit\": limit,\n",
    "        \"skip\": skip,\n",
    "        \"latest\": [\"true\"],\n",
    "        \"method\": [\"null\"],\n",
    "        \"activitySectorId\": [],\n",
    "        \"missionsTypesIds\": [\"1\"],\n",
    "        \"missionsDurations\": [],\n",
    "        \"gerographicZones\": [],\n",
    "        \"countriesIds\": [],\n",
    "        \"studiesLevelId\": [],\n",
    "        \"companiesSizes\": [],\n",
    "        \"specializationsIds\": [],\n",
    "        \"entreprisesIds\": [0],\n",
    "        \"missionStartDate\": None,\n",
    "        \"query\": None\n",
    "    }\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Effectuer la requête POST\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    # Vérifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    # Afficher le résultat\n",
    "    print(f\"Code de statut: {response.status_code}\")\n",
    "        \n",
    "    return response.json()\n",
    "\n",
    "#search_offers(1,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c4a7f",
   "metadata": {},
   "source": [
    "# API to fetch all the data for each ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd279d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offer_details(offer_id):\n",
    "    url = f\"https://civiweb-api-prd.azurewebsites.net/api/Offers/details/{offer_id}\"\n",
    "    # Headers (optionnel pour un GET simple)\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    # Effectuer la requête GET\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # Vérifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    print(\"   Récupération des données réussies\")\n",
    "    return response.json()\n",
    "\n",
    "#get_offer_details(227934)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9caeb",
   "metadata": {},
   "source": [
    "## Methods to compute application rate of the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_offer_data(offer_data):\n",
    "    \"\"\"Améliore les données avec des métriques calculées\"\"\"\n",
    "    candidates = offer_data.get('candidateCounter', 0)\n",
    "    views = offer_data.get('viewCounter', 0)\n",
    "    \n",
    "    # Calcul du taux de postulation\n",
    "    application_rate = 0\n",
    "    if views > 0:\n",
    "        application_rate = round((candidates / views) * 100, 1)\n",
    "    \n",
    "    # Catégorisation de la compétition\n",
    "    competition_level = \"FAIBLE\"\n",
    "    if application_rate > 10:\n",
    "        competition_level = \"ÉLEVÉE\"\n",
    "    elif application_rate > 5:\n",
    "        competition_level = \"MOYENNE\"\n",
    "    \n",
    "    return {\n",
    "        **offer_data,\n",
    "        \"application_rate\": application_rate,  \n",
    "        \"competition_level\": competition_level,  \n",
    "        \"candidates_count\": candidates,\n",
    "        \"views_count\": views\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea715e18",
   "metadata": {},
   "source": [
    "## Methods to clean the data, (Used in the creating chunk method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2414016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_offer_data(offer_data):\n",
    "    print(\"   Nettoyage des données\")\n",
    "    \"\"\"Nettoie et complète les données manquantes\"\"\"\n",
    "    return {\n",
    "        \"reference\": offer_data.get(\"reference\", \"N/A\"),\n",
    "        \"organizationName\": offer_data.get(\"organizationName\", \"Entreprise non spécifiée\"),\n",
    "        \"missionTitle\": offer_data.get(\"missionTitle\", \"Titre non spécifié\"),\n",
    "        \"missionDescription\": offer_data.get(\"missionDescription\", \"Description non disponible\"),\n",
    "        \"missionProfile\": offer_data.get(\"missionProfile\", \"Profil non spécifié\"),\n",
    "        \"countryNameEn\": offer_data.get(\"countryNameEn\", \"Pays non spécifié\"),\n",
    "        \"cityNameEn\": offer_data.get(\"cityNameEn\", \"Ville non spécifiée\"),\n",
    "        \"activitySectorN1\": offer_data.get(\"activitySectorN1\", \"Secteur non spécifié\"),\n",
    "        \"missionDuration\": offer_data.get(\"missionDuration\", \"Durée non spécifiée\"),\n",
    "        \"indemnite\": offer_data.get(\"indemnite\", \"Non spécifié\"),\n",
    "        \"missionStartDate\": offer_data.get(\"missionStartDate\", \"Date non spécifiée\"),\n",
    "        \"creationDate\": offer_data.get(\"creationDate\",\"Date non spécifiée\"),\n",
    "        \"contactEmail\": offer_data.get(\"contactEmail\", \"Email non disponible\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb015",
   "metadata": {},
   "source": [
    "# Creating chunks method\n",
    "\n",
    "We are dividing our chunks into content and metadata.\n",
    "\n",
    "We will only apply embedding on our content.\n",
    "\n",
    "Metadata will allow to use some filters when fetching the embeddings in the ChromaDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_chunks_for_rag(offer_data):\n",
    "    \"\"\"Crée 2 chunks optimisés pour le RAG\"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    # 1. Nettoyer les données brutes\n",
    "    cleaned_offer = clean_offer_data(offer_data)\n",
    "\n",
    "    # 2. Calculer le taux de postulation à l'offre\n",
    "    enhanced_data = enhance_offer_data(offer_data)\n",
    "\n",
    "    # 2. Extraire les métadonnées depuis les données nettoyées\n",
    "    common_metadata = {\n",
    "        \"offer_reference\": cleaned_offer.get(\"reference\"),  \n",
    "        \"company\": cleaned_offer.get(\"organizationName\"),\n",
    "        \"title\": cleaned_offer.get(\"missionTitle\"),\n",
    "        \"country\": cleaned_offer.get(\"countryNameEn\"),\n",
    "        \"city\": cleaned_offer.get(\"cityNameEn\"),\n",
    "        \"sector\": cleaned_offer.get(\"activitySectorN1\"),\n",
    "        \"duration_months\": cleaned_offer.get(\"missionDuration\"),\n",
    "        \"salary_eur\": cleaned_offer.get(\"indemnite\"),\n",
    "        \"start_date\": cleaned_offer.get(\"missionStartDate\"),\n",
    "        \"creation_date\": cleaned_offer.get(\"creationDate\"),\n",
    "        \"contact_email\": cleaned_offer.get(\"contactEmail\"),\n",
    "        # Rest is comming from enhanced_data\n",
    "        \"application_rate\": enhanced_data[\"application_rate\"],\n",
    "        \"competition_level\": enhanced_data[\"competition_level\"], \n",
    "        \"candidates_count\": enhanced_data[\"candidates_count\"],\n",
    "        \"views_count\": enhanced_data[\"views_count\"]\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    # CHUNK 1: Description de la mission\n",
    "    chunk1_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityNameEn')}, {offer_data.get('countryNameEn')}\n",
    "    Secteur d'activité: {offer_data.get('activitySectorN1')}\n",
    "    Durée: {offer_data.get('missionDuration')} mois\n",
    "    Indemnité: {offer_data.get('indemnite')} € par mois\n",
    "    Description de la mission: {offer_data.get('missionDescription', 'Non spécifiée')}\"\"\"\n",
    "\n",
    "    new_chunk = {\n",
    "        \"content\": chunk1_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"mission_description\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_description\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"   Taille du chunk de Description (caractères) : {len(new_chunk['content'])}\")\n",
    "    chunks.append(new_chunk)\n",
    "    \n",
    "    # CHUNK 2: Profil recherché\n",
    "    chunk2_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityNameEn')}, {offer_data.get('countryNameEn')}\n",
    "    Secteur d'activité: {offer_data.get('activitySectorN1')}\n",
    "    Profil recherché: {offer_data.get('missionProfile', 'Non spécifié')}\"\"\"\n",
    "\n",
    "    new_chunk2 = {\n",
    "        \"content\": chunk2_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"candidate_profile\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_profile\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    chunks.append(new_chunk2)\n",
    "    print(f\"   Taille du chunk de Profil (caractères) : {len(new_chunk2['content'])}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b65f7",
   "metadata": {},
   "source": [
    "# Create the embeding of the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af59a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration OpenAI\n",
    "api_key = os.environ.get(\"API_KEY_OPENAI\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674a7e3",
   "metadata": {},
   "source": [
    "###  Method to embed the question that we will ask the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573b4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Crée un embedding pour un texte avec OpenAI\n",
    "    \n",
    "    Args:\n",
    "        text: Le texte à embedder\n",
    "        \n",
    "    Returns:\n",
    "        Liste de floats représentant l'embedding\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"  # 1536 dimensions, $0.02/1M tokens\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b0cb4",
   "metadata": {},
   "source": [
    "###  Method to create our embeddings dataset\n",
    "\n",
    "We are using batch to optimize API calls and reduce latency. \n",
    "\n",
    "This approach processes multiple texts in a single request instead of making individual calls for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_batch(chunks: List[Dict], batch_size: int = 100) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Crée les embeddings pour tous les chunks avec traitement par batch\n",
    "    \n",
    "    Args:\n",
    "        chunks: Liste des chunks à embedder\n",
    "        batch_size: Nombre de chunks à traiter par batch (max 100 pour OpenAI)\n",
    "        \n",
    "    Returns:\n",
    "        Liste des chunks enrichis avec leurs embeddings\n",
    "    \"\"\"\n",
    "    enriched_chunks = []\n",
    "    \n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        print(f\"Traitement du batch {i//batch_size + 1} ({len(batch)} chunks)...\")\n",
    "        \n",
    "        # Extraire les contenus textuels\n",
    "        texts = [chunk[\"content\"] for chunk in batch]\n",
    "        \n",
    "        # Créer les embeddings en batch (plus efficace)\n",
    "        response = client.embeddings.create(\n",
    "            input=texts,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        # Associer chaque embedding à son chunk\n",
    "        for j, chunk in enumerate(batch):\n",
    "            enriched_chunk = chunk.copy()\n",
    "            enriched_chunk[\"embedding\"] = response.data[j].embedding\n",
    "            enriched_chunks.append(enriched_chunk)\n",
    "        \n",
    "        # Rate limiting (optionnel mais recommandé)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"✅ {len(enriched_chunks)} embeddings créés\")\n",
    "    return enriched_chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f371a9",
   "metadata": {},
   "source": [
    "# Creation of the Pipeline : create the dataset embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ÉTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=10000)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "# La structure de retour peut varier, adaptez selon l'API\n",
    "# Supposons que l'API retourne une liste d'IDs ou d'objets simplifiés\n",
    "offer_ids = []\n",
    "offer_ids = [item.get(\"id\") for item in offers_response[\"result\"] if item.get(\"id\") is not None]\n",
    "\n",
    "print(f\"✅ {len(offer_ids)} offres trouvées\")\n",
    "\n",
    "# ÉTAPE 2: Récupérer les détails et créer les chunks\n",
    "print(\"\\n[2/5] Récupération des détails et création des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids, 1):  \n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{len(offer_ids)}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"✅ {len(all_chunks)} chunks créés\\n\")\n",
    "\n",
    "# ÉTAPE 3: Créer les embeddings\n",
    "print(\"\\n[3/5] Création des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des nouvelles données...\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "# We save the current date\n",
    "update_last_refresh_date()\n",
    "\n",
    "# ÉTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre de nouvelles offres traitées: {len(offer_ids)}\")\n",
    "print(f\"Nombre de nouveaux chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des nouveaux embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estimés: ~{total_tokens:,}\")\n",
    "print(f\"Coût estimé: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de1645",
   "metadata": {},
   "source": [
    "# Creation of the Pipeline : Add new embeddings in the curent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41761b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - Nouvelles OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ÉTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=100000)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "last_refresh_date = get_last_refresh_date()\n",
    "print(f\"📅 Dernier rafraîchissement: {last_refresh_date}\")\n",
    "\n",
    "offer_ids = []\n",
    "offer_ids = [\n",
    "    item.get(\"id\") for item in offers_response[\"result\"] \n",
    "    if (item.get(\"id\") is not None and \n",
    "        datetime.fromisoformat(item.get(\"creationDate\")) > last_refresh_date)\n",
    "]\n",
    "\n",
    "print(f\"✅ {len(offer_ids)} nouvelles offres depuis le dernier rafraîchissement\")\n",
    "# Mettre à jour Last_refresh après le traitement\n",
    "update_last_refresh_date()\n",
    "\n",
    "# ÉTAPE 2: Récupérer les détails et créer les chunks\n",
    "print(\"\\n[2/5] Récupération des détails et création des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids, 1):  \n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{len(offer_ids)}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"✅ {len(all_chunks)} chunks créés\\n\")\n",
    "\n",
    "# ÉTAPE 3: Créer les embeddings\n",
    "print(\"\\n[3/5] Création des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des données...\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "\n",
    "# ÉTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre d'offres traitées: {len(offer_ids)}\")\n",
    "print(f\"Nombre de chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estimés: ~{total_tokens:,}\")\n",
    "print(f\"Coût estimé: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f7eb",
   "metadata": {},
   "source": [
    "# Now let's ask a question and embed it !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcfa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"Je Cherche un VIE de minimum 1 an, je suis orientée en Data et IA mais j'aime aussi faire du développement web. Peux tu me donner les meilleurs offres pour moi. Sachant que je cherche une offre pour Octobre 2025\"\n",
    "question = \"Je Cherche un VIE de minimum 1 an, je suis orientée en Data et IA mais j'aime aussi faire du développement web. Peux tu me donner les meilleurs offres pour moi. Si possible priorise les offres en corée du sud\"\n",
    "# question = \"Je Cherche un VIE en Asie de l'Est  pour faire de la data ou de l'IA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd87e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = np.array([get_text_embedding(question)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d5200",
   "metadata": {},
   "source": [
    "# Comparison bewtween our embedding database and our embedding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "160b890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def find_closest_embedding(\n",
    "    question_embeddings: np.array,\n",
    "    text_embeddings: np.ndarray,\n",
    "    top_n: int = 3,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Calculer les similarités avec tous les embeddings\n",
    "    similarites = cosine_similarity(question_embeddings, text_embeddings)[0]\n",
    "\n",
    "    # Récupérer les top_n index et scores\n",
    "    top_index = np.argsort(similarites)[-top_n:][::-1]  # Tri décroissant\n",
    "    top_scores = similarites[top_index]\n",
    "\n",
    "    return top_scores, top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142df887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 embeddings les plus proches:\n",
      " \n",
      "- Embedding 775: Score = 0.6460\n",
      "- Embedding 779: Score = 0.6450\n",
      "- Embedding 677: Score = 0.6409\n",
      "- Embedding 643: Score = 0.6407\n",
      "- Embedding 645: Score = 0.6396\n",
      "- Embedding 2029: Score = 0.6384\n",
      "- Embedding 1809: Score = 0.6329\n",
      "- Embedding 14: Score = 0.6293\n",
      "- Embedding 1573: Score = 0.6274\n",
      "- Embedding 2451: Score = 0.6270\n"
     ]
    }
   ],
   "source": [
    "loaded_embeddings = load_embeddings(\"vie_embeddings.npz\")\n",
    "text_embeddings = loaded_embeddings['embeddings']\n",
    "top_scores, top_index = find_closest_embedding(question_embeddings, text_embeddings, 10)\n",
    "\n",
    "top_results = []\n",
    "\n",
    "print(\"Top 10 embeddings les plus proches:\\n \")\n",
    "for score, idx in zip(top_scores, top_index):\n",
    "    print(f\"- Embedding {idx}: Score = {score:.4f}\")\n",
    "    #print(f\"metadata : {loaded_embeddings['metadata'][idx]}\")\n",
    "    #print(f\"contents : {loaded_embeddings['contents'][idx]}\")\n",
    "    top_results.append(loaded_embeddings['contents'][idx])\n",
    "\n",
    "    # loaded_embeddings['metadata'][idx] PAS UTILISER POUR L'INSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43189f",
   "metadata": {},
   "source": [
    "# We Use a LLM to answer our question using the 10 closest embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf51178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'y a pas d'offres de VIE situées en Corée du Sud dans le contexte fourni. Cependant, voici quelques offres qui pourraient correspondre à tes intérêts en Data, IA, et développement web, chacune avec une durée de VIE d'au moins 1 an :\n",
      "\n",
      "1. **Offre VIE VIE230265 - DATA SCIENTIST (H/F)**\n",
      "   - **Entreprise:** OPTIMETRIKS\n",
      "   - **Localisation:** DAKAR, SENEGAL\n",
      "   - **Profil recherché:**\n",
      "     - Solide intérêt pour le deep learning et la gestion des données\n",
      "     - Maîtrise de Python et SQL\n",
      "     - Connaissance des bibliothèques ML/DL comme TensorFlow/PyTorch, Scikit-learn, XGBoost\n",
      "     - Disponible pour au moins 12 mois\n",
      "\n",
      "2. **Offre VIE VIE229576 - DATA ENGINEER DEVELOPPER W/ FRENCH (H/F)**\n",
      "   - **Entreprise:** EXTIA\n",
      "   - **Localisation:** BUCHAREST, ROMANIA\n",
      "   - **Profil recherché:**\n",
      "     - Connaissance en ETL, Data mining, Machine learning, Big data\n",
      "     - Maîtrise des bases de l’analyse statistique\n",
      "     - Aptitude à rédiger des scripts en Python et/ou R\n",
      "     - Familiarité avec l’environnement Linux\n",
      "     - Durée du poste non spécifiée mais généralement VIE sont d'une durée minimale de 1 an.\n",
      "\n",
      "Ces offres se concentrent sur des domaines en lien avec la Data et l'IA et incluent certaines compétences en développement, telles que Python et éventuellement d'autres langages de programmation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concaténer les top-N segments en un seul contexte\n",
    "context = \"\\n\".join(top_results)\n",
    "prompt = f\"Contexte :\\n{context}\\n\\nQuestion : {question}\\nRéponse :\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Tu es un assistant spécialisé dans la recherche d'information à partir de documents fournis. Tes réponses doivent absolument provenir du contexte fourni.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
