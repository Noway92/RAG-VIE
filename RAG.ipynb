{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b523111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ceb116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Last_Refresh import get_last_refresh_date, update_last_refresh_date\n",
    "from BDD import save_embeddings_numpy, load_embeddings, append_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d49123",
   "metadata": {},
   "source": [
    "# API to fetch all VIE Id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_offers(limit=100, skip=0):\n",
    "    # URL de l'API\n",
    "    url = \"https://civiweb-api-prd.azurewebsites.net/api/Offers/search\"\n",
    "\n",
    "    # Corps de la requ√™te (payload)\n",
    "    payload = {\n",
    "        \"limit\": limit,\n",
    "        \"skip\": skip,\n",
    "        \"latest\": [\"true\"],\n",
    "        \"method\": [\"null\"],\n",
    "        \"activitySectorId\": [],\n",
    "        \"missionsTypesIds\": [\"1\"],\n",
    "        \"missionsDurations\": [],\n",
    "        \"gerographicZones\": [],\n",
    "        \"countriesIds\": [],\n",
    "        \"studiesLevelId\": [],\n",
    "        \"companiesSizes\": [],\n",
    "        \"specializationsIds\": [],\n",
    "        \"entreprisesIds\": [0],\n",
    "        \"missionStartDate\": None,\n",
    "        \"query\": None\n",
    "    }\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Effectuer la requ√™te POST\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    # V√©rifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    # Afficher le r√©sultat\n",
    "    print(f\"Code de statut: {response.status_code}\")\n",
    "        \n",
    "    return response.json()\n",
    "\n",
    "#search_offers(1,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c4a7f",
   "metadata": {},
   "source": [
    "# API to fetch all the data for each ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd279d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offer_details(offer_id):\n",
    "    url = f\"https://civiweb-api-prd.azurewebsites.net/api/Offers/details/{offer_id}\"\n",
    "    # Headers (optionnel pour un GET simple)\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    # Effectuer la requ√™te GET\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # V√©rifier le code de statut\n",
    "    response.raise_for_status()\n",
    "    print(\"   R√©cup√©ration des donn√©es r√©ussies\")\n",
    "    return response.json()\n",
    "\n",
    "#get_offer_details(227934)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9caeb",
   "metadata": {},
   "source": [
    "## Methods to compute application rate of the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_offer_data(offer_data):\n",
    "    \"\"\"Am√©liore les donn√©es avec des m√©triques calcul√©es\"\"\"\n",
    "    candidates = offer_data.get('candidateCounter', 0)\n",
    "    views = offer_data.get('viewCounter', 0)\n",
    "    \n",
    "    # Calcul du taux de postulation\n",
    "    application_rate = 0\n",
    "    if views > 0:\n",
    "        application_rate = round((candidates / views) * 100, 1)\n",
    "    \n",
    "    # Cat√©gorisation de la comp√©tition\n",
    "    competition_level = \"FAIBLE\"\n",
    "    if application_rate > 10:\n",
    "        competition_level = \"√âLEV√âE\"\n",
    "    elif application_rate > 5:\n",
    "        competition_level = \"MOYENNE\"\n",
    "    \n",
    "    return {\n",
    "        **offer_data,\n",
    "        \"application_rate\": application_rate,  \n",
    "        \"competition_level\": competition_level,  \n",
    "        \"candidates_count\": candidates,\n",
    "        \"views_count\": views\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea715e18",
   "metadata": {},
   "source": [
    "## Methods to clean the data, (Used in the creating chunk method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2414016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_offer_data(offer_data):\n",
    "    print(\"   Nettoyage des donn√©es\")\n",
    "    \"\"\"Nettoie et compl√®te les donn√©es manquantes\"\"\"\n",
    "    return {\n",
    "        \"reference\": offer_data.get(\"reference\", \"N/A\"),\n",
    "        \"organizationName\": offer_data.get(\"organizationName\", \"Entreprise non sp√©cifi√©e\"),\n",
    "        \"missionTitle\": offer_data.get(\"missionTitle\", \"Titre non sp√©cifi√©\"),\n",
    "        \"missionDescription\": offer_data.get(\"missionDescription\", \"Description non disponible\"),\n",
    "        \"missionProfile\": offer_data.get(\"missionProfile\", \"Profil non sp√©cifi√©\"),\n",
    "        \"countryNameEn\": offer_data.get(\"countryNameEn\", \"Pays non sp√©cifi√©\"),\n",
    "        \"cityNameEn\": offer_data.get(\"cityNameEn\", \"Ville non sp√©cifi√©e\"),\n",
    "        \"activitySectorN1\": offer_data.get(\"activitySectorN1\", \"Secteur non sp√©cifi√©\"),\n",
    "        \"missionDuration\": offer_data.get(\"missionDuration\", \"Dur√©e non sp√©cifi√©e\"),\n",
    "        \"indemnite\": offer_data.get(\"indemnite\", \"Non sp√©cifi√©\"),\n",
    "        \"missionStartDate\": offer_data.get(\"missionStartDate\", \"Date non sp√©cifi√©e\"),\n",
    "        \"creationDate\": offer_data.get(\"creationDate\",\"Date non sp√©cifi√©e\"),\n",
    "        \"contactEmail\": offer_data.get(\"contactEmail\", \"Email non disponible\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb015",
   "metadata": {},
   "source": [
    "# Creating chunks method\n",
    "\n",
    "We are dividing our chunks into content and metadata.\n",
    "\n",
    "We will only apply embedding on our content.\n",
    "\n",
    "Metadata will allow to use some filters when fetching the embeddings in the ChromaDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_chunks_for_rag(offer_data):\n",
    "    \"\"\"Cr√©e 2 chunks optimis√©s pour le RAG\"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    # 1. Nettoyer les donn√©es brutes\n",
    "    cleaned_offer = clean_offer_data(offer_data)\n",
    "\n",
    "    # 2. Calculer le taux de postulation √† l'offre\n",
    "    enhanced_data = enhance_offer_data(offer_data)\n",
    "\n",
    "    # 2. Extraire les m√©tadonn√©es depuis les donn√©es nettoy√©es\n",
    "    common_metadata = {\n",
    "        \"offer_reference\": cleaned_offer.get(\"reference\"),  \n",
    "        \"company\": cleaned_offer.get(\"organizationName\"),\n",
    "        \"title\": cleaned_offer.get(\"missionTitle\"),\n",
    "        \"country\": cleaned_offer.get(\"countryNameEn\"),\n",
    "        \"city\": cleaned_offer.get(\"cityNameEn\"),\n",
    "        \"sector\": cleaned_offer.get(\"activitySectorN1\"),\n",
    "        \"duration_months\": cleaned_offer.get(\"missionDuration\"),\n",
    "        \"salary_eur\": cleaned_offer.get(\"indemnite\"),\n",
    "        \"start_date\": cleaned_offer.get(\"missionStartDate\"),\n",
    "        \"creation_date\": cleaned_offer.get(\"creationDate\"),\n",
    "        \"contact_email\": cleaned_offer.get(\"contactEmail\"),\n",
    "        # Rest is comming from enhanced_data\n",
    "        \"application_rate\": enhanced_data[\"application_rate\"],\n",
    "        \"competition_level\": enhanced_data[\"competition_level\"], \n",
    "        \"candidates_count\": enhanced_data[\"candidates_count\"],\n",
    "        \"views_count\": enhanced_data[\"views_count\"]\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    # CHUNK 1: Description de la mission\n",
    "    chunk1_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityNameEn')}, {offer_data.get('countryNameEn')}\n",
    "    Secteur d'activit√©: {offer_data.get('activitySectorN1')}\n",
    "    Dur√©e: {offer_data.get('missionDuration')} mois\n",
    "    Indemnit√©: {offer_data.get('indemnite')} ‚Ç¨ par mois\n",
    "    Description de la mission: {offer_data.get('missionDescription', 'Non sp√©cifi√©e')}\"\"\"\n",
    "\n",
    "    new_chunk = {\n",
    "        \"content\": chunk1_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"mission_description\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_description\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"   Taille du chunk de Description (caract√®res) : {len(new_chunk['content'])}\")\n",
    "    chunks.append(new_chunk)\n",
    "    \n",
    "    # CHUNK 2: Profil recherch√©\n",
    "    chunk2_content = f\"\"\"Offre VIE {offer_data.get('reference')} - {offer_data.get('missionTitle')}\n",
    "    Entreprise: {offer_data.get('organizationName')}\n",
    "    Localisation: {offer_data.get('cityNameEn')}, {offer_data.get('countryNameEn')}\n",
    "    Secteur d'activit√©: {offer_data.get('activitySectorN1')}\n",
    "    Profil recherch√©: {offer_data.get('missionProfile', 'Non sp√©cifi√©')}\"\"\"\n",
    "\n",
    "    new_chunk2 = {\n",
    "        \"content\": chunk2_content,\n",
    "        \"metadata\": {\n",
    "            **common_metadata,\n",
    "            \"chunk_type\": \"candidate_profile\",\n",
    "            \"chunk_id\": f\"{offer_data.get('id')}_profile\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    chunks.append(new_chunk2)\n",
    "    print(f\"   Taille du chunk de Profil (caract√®res) : {len(new_chunk2['content'])}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b65f7",
   "metadata": {},
   "source": [
    "# Create the embeding of the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af59a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration OpenAI\n",
    "api_key = os.environ.get(\"API_KEY_OPENAI\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674a7e3",
   "metadata": {},
   "source": [
    "###  Method to embed the question that we will ask the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573b4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Cr√©e un embedding pour un texte avec OpenAI\n",
    "    \n",
    "    Args:\n",
    "        text: Le texte √† embedder\n",
    "        \n",
    "    Returns:\n",
    "        Liste de floats repr√©sentant l'embedding\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"  # 1536 dimensions, $0.02/1M tokens\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b0cb4",
   "metadata": {},
   "source": [
    "###  Method to create our embeddings dataset\n",
    "\n",
    "We are using batch to optimize API calls and reduce latency. \n",
    "\n",
    "This approach processes multiple texts in a single request instead of making individual calls for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_batch(chunks: List[Dict], batch_size: int = 100) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Cr√©e les embeddings pour tous les chunks avec traitement par batch\n",
    "    \n",
    "    Args:\n",
    "        chunks: Liste des chunks √† embedder\n",
    "        batch_size: Nombre de chunks √† traiter par batch (max 100 pour OpenAI)\n",
    "        \n",
    "    Returns:\n",
    "        Liste des chunks enrichis avec leurs embeddings\n",
    "    \"\"\"\n",
    "    enriched_chunks = []\n",
    "    \n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        print(f\"Traitement du batch {i//batch_size + 1} ({len(batch)} chunks)...\")\n",
    "        \n",
    "        # Extraire les contenus textuels\n",
    "        texts = [chunk[\"content\"] for chunk in batch]\n",
    "        \n",
    "        # Cr√©er les embeddings en batch (plus efficace)\n",
    "        response = client.embeddings.create(\n",
    "            input=texts,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        # Associer chaque embedding √† son chunk\n",
    "        for j, chunk in enumerate(batch):\n",
    "            enriched_chunk = chunk.copy()\n",
    "            enriched_chunk[\"embedding\"] = response.data[j].embedding\n",
    "            enriched_chunks.append(enriched_chunk)\n",
    "        \n",
    "        # Rate limiting (optionnel mais recommand√©)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"‚úÖ {len(enriched_chunks)} embeddings cr√©√©s\")\n",
    "    return enriched_chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f371a9",
   "metadata": {},
   "source": [
    "# Creation of the Pipeline : create the dataset embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# √âTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=10000)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "# La structure de retour peut varier, adaptez selon l'API\n",
    "# Supposons que l'API retourne une liste d'IDs ou d'objets simplifi√©s\n",
    "offer_ids = []\n",
    "offer_ids = [item.get(\"id\") for item in offers_response[\"result\"] if item.get(\"id\") is not None]\n",
    "\n",
    "print(f\"‚úÖ {len(offer_ids)} offres trouv√©es\")\n",
    "\n",
    "# √âTAPE 2: R√©cup√©rer les d√©tails et cr√©er les chunks\n",
    "print(\"\\n[2/5] R√©cup√©ration des d√©tails et cr√©ation des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids, 1):  \n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{len(offer_ids)}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"‚úÖ {len(all_chunks)} chunks cr√©√©s\\n\")\n",
    "\n",
    "# √âTAPE 3: Cr√©er les embeddings\n",
    "print(\"\\n[3/5] Cr√©ation des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des nouvelles donn√©es...\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "# We save the current date\n",
    "update_last_refresh_date()\n",
    "\n",
    "# √âTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre de nouvelles offres trait√©es: {len(offer_ids)}\")\n",
    "print(f\"Nombre de nouveaux chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des nouveaux embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estim√©s: ~{total_tokens:,}\")\n",
    "print(f\"Co√ªt estim√©: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de1645",
   "metadata": {},
   "source": [
    "# Creation of the Pipeline : Add new embeddings in the curent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41761b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PIPELINE RAG - Nouvelles OFFRES VIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# √âTAPE 1: Rechercher les offres\n",
    "print(\"\\n[1/5] Recherche des offres VIE...\")\n",
    "offers_response = search_offers(limit=100000)  # Ajustez la limite selon vos besoins\n",
    "\n",
    "last_refresh_date = get_last_refresh_date()\n",
    "print(f\"üìÖ Dernier rafra√Æchissement: {last_refresh_date}\")\n",
    "\n",
    "offer_ids = []\n",
    "offer_ids = [\n",
    "    item.get(\"id\") for item in offers_response[\"result\"] \n",
    "    if (item.get(\"id\") is not None and \n",
    "        datetime.fromisoformat(item.get(\"creationDate\")) > last_refresh_date)\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ {len(offer_ids)} nouvelles offres depuis le dernier rafra√Æchissement\")\n",
    "# Mettre √† jour Last_refresh apr√®s le traitement\n",
    "update_last_refresh_date()\n",
    "\n",
    "# √âTAPE 2: R√©cup√©rer les d√©tails et cr√©er les chunks\n",
    "print(\"\\n[2/5] R√©cup√©ration des d√©tails et cr√©ation des chunks...\")\n",
    "all_chunks = []\n",
    "    \n",
    "\n",
    "for i, offer_id in enumerate(offer_ids, 1):  \n",
    "    try:\n",
    "        print(f\"  Traitement offre {i}/{len(offer_ids)}: {offer_id}\")\n",
    "        offer_details = get_offer_details(offer_id)\n",
    "        chunks = create_chunks_for_rag(offer_details)\n",
    "        all_chunks.extend(chunks)\n",
    "        time.sleep(0.2)  # Rate limiting pour l'API Civiweb\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Erreur pour l'offre {offer_id}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"‚úÖ {len(all_chunks)} chunks cr√©√©s\\n\")\n",
    "\n",
    "# √âTAPE 3: Cr√©er les embeddings\n",
    "print(\"\\n[3/5] Cr√©ation des embeddings OpenAI...\")\n",
    "chunks_with_embeddings = create_embeddings_batch(all_chunks)\n",
    "\n",
    "\n",
    "print(\"\\n[4/5] Sauvegarde des donn√©es...\")\n",
    "save_embeddings_numpy(chunks_with_embeddings, \"vie_embeddings.npz\")\n",
    "\n",
    "\n",
    "# √âTAPE 5: Statistiques\n",
    "print(\"\\n[5/5] Statistiques finales\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nombre d'offres trait√©es: {len(offer_ids)}\")\n",
    "print(f\"Nombre de chunks: {len(chunks_with_embeddings)}\")\n",
    "print(f\"Dimension des embeddings: {len(chunks_with_embeddings[0]['embedding'])}\")\n",
    "\n",
    "# Calculer la taille totale\n",
    "total_tokens = sum(len(c['content']) // 4 for c in chunks_with_embeddings)\n",
    "print(f\"Tokens estim√©s: ~{total_tokens:,}\")\n",
    "print(f\"Co√ªt estim√©: ~${(total_tokens / 1_000_000) * 0.02:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f7eb",
   "metadata": {},
   "source": [
    "# Now let's ask a question and embed it !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcfa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"Je Cherche un VIE de minimum 1 an, je suis orient√©e en Data et IA mais j'aime aussi faire du d√©veloppement web. Peux tu me donner les meilleurs offres pour moi. Sachant que je cherche une offre pour Octobre 2025\"\n",
    "question = \"Je Cherche un VIE de minimum 1 an, je suis orient√©e en Data et IA mais j'aime aussi faire du d√©veloppement web. Peux tu me donner les meilleurs offres pour moi. Si possible priorise les offres en cor√©e du sud\"\n",
    "# question = \"Je Cherche un VIE en Asie de l'Est  pour faire de la data ou de l'IA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd87e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = np.array([get_text_embedding(question)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d5200",
   "metadata": {},
   "source": [
    "# Comparison bewtween our embedding database and our embedding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "160b890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def find_closest_embedding(\n",
    "    question_embeddings: np.array,\n",
    "    text_embeddings: np.ndarray,\n",
    "    top_n: int = 3,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Calculer les similarit√©s avec tous les embeddings\n",
    "    similarites = cosine_similarity(question_embeddings, text_embeddings)[0]\n",
    "\n",
    "    # R√©cup√©rer les top_n index et scores\n",
    "    top_index = np.argsort(similarites)[-top_n:][::-1]  # Tri d√©croissant\n",
    "    top_scores = similarites[top_index]\n",
    "\n",
    "    return top_scores, top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142df887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 embeddings les plus proches:\n",
      " \n",
      "- Embedding 775: Score = 0.6460\n",
      "- Embedding 779: Score = 0.6450\n",
      "- Embedding 677: Score = 0.6409\n",
      "- Embedding 643: Score = 0.6407\n",
      "- Embedding 645: Score = 0.6396\n",
      "- Embedding 2029: Score = 0.6384\n",
      "- Embedding 1809: Score = 0.6329\n",
      "- Embedding 14: Score = 0.6293\n",
      "- Embedding 1573: Score = 0.6274\n",
      "- Embedding 2451: Score = 0.6270\n"
     ]
    }
   ],
   "source": [
    "loaded_embeddings = load_embeddings(\"vie_embeddings.npz\")\n",
    "text_embeddings = loaded_embeddings['embeddings']\n",
    "top_scores, top_index = find_closest_embedding(question_embeddings, text_embeddings, 10)\n",
    "\n",
    "top_results = []\n",
    "\n",
    "print(\"Top 10 embeddings les plus proches:\\n \")\n",
    "for score, idx in zip(top_scores, top_index):\n",
    "    print(f\"- Embedding {idx}: Score = {score:.4f}\")\n",
    "    #print(f\"metadata : {loaded_embeddings['metadata'][idx]}\")\n",
    "    #print(f\"contents : {loaded_embeddings['contents'][idx]}\")\n",
    "    top_results.append(loaded_embeddings['contents'][idx])\n",
    "\n",
    "    # loaded_embeddings['metadata'][idx] PAS UTILISER POUR L'INSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43189f",
   "metadata": {},
   "source": [
    "# We Use a LLM to answer our question using the 10 closest embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf51178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'y a pas d'offres de VIE situ√©es en Cor√©e du Sud dans le contexte fourni. Cependant, voici quelques offres qui pourraient correspondre √† tes int√©r√™ts en Data, IA, et d√©veloppement web, chacune avec une dur√©e de VIE d'au moins 1 an :\n",
      "\n",
      "1. **Offre VIE VIE230265 - DATA SCIENTIST (H/F)**\n",
      "   - **Entreprise:** OPTIMETRIKS\n",
      "   - **Localisation:** DAKAR, SENEGAL\n",
      "   - **Profil recherch√©:**\n",
      "     - Solide int√©r√™t pour le deep learning et la gestion des donn√©es\n",
      "     - Ma√Ætrise de Python et SQL\n",
      "     - Connaissance des biblioth√®ques ML/DL comme TensorFlow/PyTorch, Scikit-learn, XGBoost\n",
      "     - Disponible pour au moins 12 mois\n",
      "\n",
      "2. **Offre VIE VIE229576 - DATA ENGINEER DEVELOPPER W/ FRENCH (H/F)**\n",
      "   - **Entreprise:** EXTIA\n",
      "   - **Localisation:** BUCHAREST, ROMANIA\n",
      "   - **Profil recherch√©:**\n",
      "     - Connaissance en ETL, Data mining, Machine learning, Big data\n",
      "     - Ma√Ætrise des bases de l‚Äôanalyse statistique\n",
      "     - Aptitude √† r√©diger des scripts en Python et/ou R\n",
      "     - Familiarit√© avec l‚Äôenvironnement Linux\n",
      "     - Dur√©e du poste non sp√©cifi√©e mais g√©n√©ralement VIE sont d'une dur√©e minimale de 1 an.\n",
      "\n",
      "Ces offres se concentrent sur des domaines en lien avec la Data et l'IA et incluent certaines comp√©tences en d√©veloppement, telles que Python et √©ventuellement d'autres langages de programmation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concat√©ner les top-N segments en un seul contexte\n",
    "context = \"\\n\".join(top_results)\n",
    "prompt = f\"Contexte :\\n{context}\\n\\nQuestion : {question}\\nR√©ponse :\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Tu es un assistant sp√©cialis√© dans la recherche d'information √† partir de documents fournis. Tes r√©ponses doivent absolument provenir du contexte fourni.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
